<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://uv-xiao.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://uv-xiao.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-07-02T19:02:17+00:00</updated><id>https://uv-xiao.github.io/feed.xml</id><title type="html">uv-xiao</title><subtitle>Ph.D. candidate at Peking University focusing on software techniques for architecture-hardware co-specialization. </subtitle><entry><title type="html">What if You Never Had to Choose? A Journey into E-graphs and Equality Saturation</title><link href="https://uv-xiao.github.io/blog/2025/egg-things/" rel="alternate" type="text/html" title="What if You Never Had to Choose? A Journey into E-graphs and Equality Saturation"/><published>2025-07-02T00:00:00+00:00</published><updated>2025-07-02T00:00:00+00:00</updated><id>https://uv-xiao.github.io/blog/2025/egg-things</id><content type="html" xml:base="https://uv-xiao.github.io/blog/2025/egg-things/"><![CDATA[<p>I still remember my first serious attempt at writing a compiler optimizer. I had this clever rule: <code class="language-plaintext highlighter-rouge">(a * 2) / 2 → a</code>. Simple, right? But then I realized that by eagerly applying it, I was destroying the pattern <code class="language-plaintext highlighter-rouge">(a * 2)</code> that another rule needed for vectorization. This is the optimizer’s eternal dilemma: every choice you make closes doors to other opportunities.</p> <p>For decades, we’ve played this high-stakes game of optimization whack-a-mole, carefully ordering our transformations and hoping we don’t paint ourselves into a corner. But what if I told you there’s a way to have your cake and eat it too? What if you could apply ALL your optimizations at once and then pick the best result?</p> <p>Welcome to the world of <strong>e-graphs</strong> and <strong>equality saturation</strong> - where we don’t choose between optimizations, we choose from <em>all possible</em> optimizations. It’s like having a time machine for your compiler passes, except it actually works.</p> <h2 id="the-problem-why-traditional-optimization-is-like-playing-jenga">The Problem: Why Traditional Optimization is Like Playing Jenga</h2> <p>Before we dive into the solution, let’s understand why optimization is so darn hard. Traditional compilers use <strong>term rewriting</strong> - they see a pattern in your code and replace it with something better. Sounds great, right? Well…</p> <h2 id="term-rewriting-the-old-school-approach">Term Rewriting: The Old School Approach</h2> <h3 id="how-it-works-the-cookbook-analogy">How It Works (The Cookbook Analogy)</h3> <p>Think of <strong>term rewriting</strong> [Baader &amp; Nipkow, “Term rewriting and all that,” 1998] like following a very literal recipe. You have your ingredients (the program), and a set of substitution rules (the recipe steps). When you see “2 cups of sugar”, you can replace it with “1 cup of honey”.</p> <p>In programming terms:</p> <ul> <li><strong>Terms</strong>: Your code expressions, like <code class="language-plaintext highlighter-rouge">(a + 0) + (b + 0)</code></li> <li><strong>Rules</strong>: Transformations like “x + 0 → x” (because adding zero is pointless)</li> <li><strong>Context</strong>: The surrounding code that doesn’t change</li> </ul> <p><strong>A Simple Example:</strong> Let’s optimize <code class="language-plaintext highlighter-rouge">(a + 0) + (b + 0)</code> with the rule <code class="language-plaintext highlighter-rouge">x + 0 → x</code>:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Original: (a + 0) + (b + 0)
Apply rule to first part: a + (b + 0)
Apply rule to second part: a + b
</code></pre></div></div> <p>Seems great! But here’s the catch…</p> <h3 id="the-problems-why-this-gets-messy-fast">The Problems: Why This Gets Messy Fast</h3> <p><strong>The Termination Trap:</strong> Sometimes rules can ping-pong forever:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>x + y → y + x  (commutivity)
y + x → x + y  (oops, infinite loop!)
</code></pre></div></div> <p><strong>The Confluence Conundrum:</strong> Different rule orders give different results:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(a * 2) / 2
  ↓ (optimize multiply)     ↓ (optimize divide)
(a &lt;&lt; 1) / 2                a * (2/2)
  ↓                         ↓
???                         a
</code></pre></div></div> <p>One path leads to <code class="language-plaintext highlighter-rouge">a</code>, the other to… who knows? This is why compiler writers lose sleep.</p> <h3 id="the-band-aid-rewrite-strategies">The Band-Aid: Rewrite Strategies</h3> <p>Compiler writers tried to fix this with “strategies” - basically recipes for <em>how</em> to apply rules. It’s like saying “always start cooking from the outside in” or “season as you go”.</p> <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// "Apply this optimization to the outermost loops first"</span>
<span class="k">def</span> <span class="nf">outermost</span> <span class="k">=</span> <span class="n">applyToOuterLoopsFirst</span>

<span class="c1">// "Then tile the matrix multiply"</span>
<span class="nf">tile</span><span class="o">(</span><span class="mi">32</span><span class="o">,</span><span class="mi">32</span><span class="o">)</span> <span class="n">after</span> <span class="n">outermost</span>
</code></pre></div></div> <p>But this is still just organized guessing. What if the optimal strategy for one program is terrible for another? Enter e-graphs, stage left.</p> <h2 id="e-graphs-the-keep-everything-revolution">E-graphs: The “Keep Everything” Revolution</h2> <h3 id="the-big-idea-detectives-corkboard-analogy">The Big Idea (Detective’s Corkboard Analogy)</h3> <p>Imagine you’re a detective trying to solve a case. Traditional optimization is like having to choose one lead and throw away all the others. E-graphs [Nelson &amp; Oppen, “Fast decision procedures based on congruence closure,” 1980]? That’s like having a corkboard where you can pin up EVERY clue and connect them with red string.</p> <p>An <strong>e-graph</strong> (equality graph) is a data structure that stores multiple equivalent expressions simultaneously. When you discover that <code class="language-plaintext highlighter-rouge">x * 2</code> equals <code class="language-plaintext highlighter-rouge">x &lt;&lt; 1</code>, you don’t replace one with the other - you just connect them with a piece of string saying “these are the same!”</p> <p>The magic is that e-graphs store all this information incredibly efficiently by sharing common sub-expressions. It’s like realizing that five different theories all use the same piece of evidence, so you only need to pin it up once.</p> <h3 id="how-e-graphs-actually-work">How E-graphs Actually Work</h3> <p>An e-graph has two main concepts:</p> <p><strong>E-nodes</strong>: These are your actual expressions, like <code class="language-plaintext highlighter-rouge">a + b</code> or <code class="language-plaintext highlighter-rouge">foo(x, y)</code>. Think of them as the individual clues on your corkboard.</p> <p><strong>E-classes</strong>: These are groups of equivalent e-nodes. If <code class="language-plaintext highlighter-rouge">x * 2</code>, <code class="language-plaintext highlighter-rouge">x &lt;&lt; 1</code>, and <code class="language-plaintext highlighter-rouge">x + x</code> are all equivalent, they live in the same e-class. It’s like having a circle drawn around related clues.</p> <p>The clever bit? E-graphs use a <strong>union-find</strong> data structure (think: extremely efficient way to group things) to keep track of which expressions are equivalent. When you discover a new equivalence, you just union two e-classes together. Boom! Instant optimization propagation.</p> <h3 id="the-e-graph-api-just-four-operations">The E-graph API: Just Four Operations</h3> <p>E-graphs are beautifully simple. You only need four operations:</p> <ol> <li><strong>add(expression)</strong>: “Hey e-graph, remember this expression”</li> <li><strong>merge(id1, id2)</strong>: “BTW, these two things are equal”</li> <li><strong>find(id)</strong>: “What group is this expression in?”</li> <li><strong>ematch(pattern)</strong>: “Find me all expressions that look like this”</li> </ol> <p>That’s it! With these four operations, you can build incredibly sophisticated optimizers. It’s like LEGO blocks for compiler writers.</p> <h3 id="e-matching-finding-patterns-in-the-chaos">E-matching: Finding Patterns in the Chaos</h3> <p>E-matching is like playing Where’s Waldo, but Waldo could be wearing different outfits (equivalent expressions). You give it a pattern like “find all <code class="language-plaintext highlighter-rouge">x + 0</code> expressions” and it searches through the entire e-graph.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">find_optimization_opportunities</span><span class="p">(</span><span class="n">pattern</span><span class="p">,</span> <span class="n">egraph</span><span class="p">):</span>
    <span class="c1"># "Show me everything that looks like x + 0"
</span>    <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">egraph</span><span class="p">.</span><span class="nf">all_groups</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">expression</span> <span class="ow">in</span> <span class="n">group</span><span class="p">.</span><span class="n">expressions</span><span class="p">:</span>
            <span class="k">if</span> <span class="nf">looks_like</span><span class="p">(</span><span class="n">pattern</span><span class="p">,</span> <span class="n">expression</span><span class="p">):</span>
                <span class="k">yield</span> <span class="sh">"</span><span class="s">Found one!</span><span class="sh">"</span><span class="p">,</span> <span class="n">expression</span>
</code></pre></div></div> <p>The beautiful part? Because the e-graph maintains equivalences, when you find <code class="language-plaintext highlighter-rouge">(a * 2) + 0</code>, you automatically know about <code class="language-plaintext highlighter-rouge">(a &lt;&lt; 1) + 0</code> too!</p> <h3 id="the-magic-non-destructive-rewriting">The Magic: Non-Destructive Rewriting</h3> <p>Here’s where e-graphs blow your mind. In traditional rewriting:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(a * 2) / 2 → a    // Bye bye, original expression!
</code></pre></div></div> <p>In e-graphs:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(a * 2) / 2 ≅ a    // Both exist! They're friends now!
</code></pre></div></div> <p>The process:</p> <ol> <li>Find all instances of your pattern (like <code class="language-plaintext highlighter-rouge">(x * 2) / 2</code>)</li> <li>Calculate what they should become (<code class="language-plaintext highlighter-rouge">x</code>)</li> <li>Don’t replace! Just merge the e-classes</li> </ol> <p>It’s like saying “these two expressions are pen pals” instead of “this expression is dead to me.” Much more civilized.</p> <h3 id="visual-example-the-old-way-vs-the-e-graph-way">Visual Example: The Old Way vs. The E-graph Way</h3> <pre><code class="language-mermaid">graph TB
    subgraph "Traditional Rewriting"
        A1["(a * 2) / 2"] --&gt;|destroy| A2["(a &lt;&lt; 1) / 2"]
        A2 --&gt;|destroy| A3["a"]
        style A1 fill:#ffcccc,stroke:#ff0000,stroke-width:2px,text-decoration:line-through
        style A2 fill:#ffcccc,stroke:#ff0000,stroke-width:2px,text-decoration:line-through
    end
    
    subgraph "E-graph Approach"
        B1["E-class 1"]
        B1 --&gt; B2["(a * 2) / 2"]
        B1 --&gt; B3["(a &lt;&lt; 1) / 2"]
        B1 --&gt; B4["a"]
        B1 --&gt; B5["..."]]
        style B1 fill:#ccffcc,stroke:#00ff00,stroke-width:2px
    end
</code></pre> <h2 id="equality-saturation-going-full-detective-mode">Equality Saturation: Going Full Detective Mode</h2> <h3 id="the-phase-ordering-problem-why-order-matters">The Phase Ordering Problem (Why Order Matters)</h3> <p>Remember that game where you have to get the fox, chicken, and grain across the river? Traditional optimization is like that, but with 1000 items and no clear rules. This is the dreaded <strong>phase ordering problem</strong> [Tate et al., “Equality saturation: A new approach to optimization,” POPL 2009].</p> <p>Example with <code class="language-plaintext highlighter-rouge">(a * 2) / 2</code>:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Path 1: Optimize multiplies first
(a * 2) / 2 → (a &lt;&lt; 1) / 2 → ... → ???

Path 2: Apply algebra first  
(a * 2) / 2 → a * (2/2) → a * 1 → a ✓
</code></pre></div></div> <p>One path gets you the optimal result, the other gets you stuck. But how do you know which path to take? You don’t. Until now.</p> <h3 id="equality-saturation-the-try-everything-algorithm">Equality Saturation: The “Try Everything” Algorithm</h3> <p>Here’s the brilliant insight: What if we just… didn’t choose? What if we applied ALL the optimizations at once and sorted it out later?</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">equality_saturation</span><span class="p">(</span><span class="n">expr</span><span class="p">,</span> <span class="n">rules</span><span class="p">):</span>
    <span class="n">egraph</span> <span class="o">=</span> <span class="nf">start_with</span><span class="p">(</span><span class="n">expr</span><span class="p">)</span>
    
    <span class="k">while</span> <span class="sh">"</span><span class="s">we</span><span class="sh">'</span><span class="s">re still finding new stuff</span><span class="sh">"</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">rule</span> <span class="ow">in</span> <span class="n">rules</span><span class="p">:</span>
            <span class="c1"># Find everywhere this rule could apply
</span>            <span class="n">matches</span> <span class="o">=</span> <span class="n">egraph</span><span class="p">.</span><span class="nf">find_pattern</span><span class="p">(</span><span class="n">rule</span><span class="p">.</span><span class="n">pattern</span><span class="p">)</span>
            
            <span class="k">for</span> <span class="n">match</span> <span class="ow">in</span> <span class="n">matches</span><span class="p">:</span>
                <span class="c1"># Apply the rule (non-destructively!)
</span>                <span class="n">new_expr</span> <span class="o">=</span> <span class="n">rule</span><span class="p">.</span><span class="nf">apply_to</span><span class="p">(</span><span class="n">match</span><span class="p">)</span>
                <span class="n">egraph</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="n">new_expr</span><span class="p">)</span>
                <span class="n">egraph</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">match</span><span class="p">,</span> <span class="n">new_expr</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="sh">"</span><span class="s">nothing new was discovered</span><span class="sh">"</span><span class="p">:</span>
            <span class="k">break</span>  <span class="c1"># We're saturated!
</span>    
    <span class="k">return</span> <span class="n">egraph</span><span class="p">.</span><span class="nf">pick_best_expression</span><span class="p">()</span>
</code></pre></div></div> <p><strong>The Algorithm in Plain English:</strong></p> <ol> <li>Start with your expression</li> <li>Apply every possible rule everywhere you can</li> <li>Keep all the results (don’t throw anything away!)</li> <li>Repeat until you can’t find any new equivalences</li> <li>Pick the best final result</li> </ol> <p>It’s like letting a hyperactive monkey loose in an optimization candy store, then picking the best candy it found. Chaotic? Yes. Effective? Absolutely.</p> <h3 id="extraction-picking-the-best-from-the-buffet">Extraction: Picking the Best from the Buffet</h3> <p>Okay, so we’ve applied every optimization known to mankind and our e-graph is stuffed with equivalent expressions. Now what? We need to pick the “best” one. This is called <strong>extraction</strong>.</p> <p><strong>The Catch:</strong> Remember when I said this was all magical? Well, here’s the punchline - picking the optimal expression from an e-graph is NP-hard. It’s like being told the treasure is buried “somewhere on Earth.” Thanks, very helpful.</p> <p><strong>The Problem:</strong></p> <ul> <li>You need to pick one expression from each e-class</li> <li>But the choices are interdependent (picking <code class="language-plaintext highlighter-rouge">a + b</code> in one place might make <code class="language-plaintext highlighter-rouge">b + a</code> better elsewhere)</li> <li>Finding the global optimum is computationally brutal</li> </ul> <p>But don’t worry! We have tricks up our sleeve…</p> <h4 id="approach-1-the-mathematicians-solution-ilp">Approach 1: The Mathematician’s Solution (ILP)</h4> <p>You can formulate extraction as an Integer Linear Programming problem. Basically, you’re asking a very expensive solver to find the optimal solution.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Minimize: total cost of selected expressions
Subject to:
  - Pick at least one thing from each e-class
  - If you pick an expression, pick all its children
  - Don't create cycles (no circular reasoning!)
</code></pre></div></div> <p><strong>Pro:</strong> Guaranteed optimal solution! <strong>Con:</strong> Might take until the heat death of the universe for large programs.</p> <h4 id="approach-2-the-graph-theorists-dream-dynamic-programming">Approach 2: The Graph Theorist’s Dream (Dynamic Programming)</h4> <p>If your e-graph has nice structure (technically: low treewidth), you can use dynamic programming. It’s like solving a puzzle by breaking it into smaller, manageable pieces.</p> <p><strong>The Idea:</strong></p> <ul> <li>Decompose the e-graph into a tree of “bags”</li> <li>Solve each bag independently</li> <li>Combine solutions cleverly</li> </ul> <p><strong>When It Works:</strong> Great for e-graphs that look like trees with a few extra edges <strong>When It Doesn’t:</strong> Not so great for e-graphs that look like hairballs</p> <h4 id="approach-3-the-engineers-good-enough-heuristics">Approach 3: The Engineer’s “Good Enough” (Heuristics)</h4> <p>Most real systems say “perfect is the enemy of good” and use heuristics:</p> <p><strong>Bottom-up Greedy:</strong> Start from the leaves, pick the cheapest option at each level</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">extract_greedy</span><span class="p">(</span><span class="n">eclass</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">eclass</span><span class="p">.</span><span class="nf">is_leaf</span><span class="p">():</span>
        <span class="k">return</span> <span class="nf">cheapest_option</span><span class="p">(</span><span class="n">eclass</span><span class="p">)</span>
    
    <span class="c1"># Try each option with greedy children
</span>    <span class="n">best</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">for</span> <span class="n">expr</span> <span class="ow">in</span> <span class="n">eclass</span><span class="p">:</span>
        <span class="n">cost</span> <span class="o">=</span> <span class="n">expr</span><span class="p">.</span><span class="n">cost</span> <span class="o">+</span> <span class="nf">sum</span><span class="p">(</span><span class="nf">extract_greedy</span><span class="p">(</span><span class="n">child</span><span class="p">)</span> <span class="k">for</span> <span class="n">child</span> <span class="ow">in</span> <span class="n">expr</span><span class="p">.</span><span class="n">children</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cost</span> <span class="o">&lt;</span> <span class="n">best</span><span class="p">.</span><span class="n">cost</span><span class="p">:</span>
            <span class="n">best</span> <span class="o">=</span> <span class="n">expr</span>
    <span class="k">return</span> <span class="n">best</span>
</code></pre></div></div> <p><strong>Pool Extraction:</strong> The “throw spaghetti at the wall” approach:</p> <ol> <li>Generate 100 different extractions using various strategies</li> <li>Add some random ones for spice</li> <li>Evaluate them all</li> <li>Pick the winner</li> </ol> <p>Surprisingly effective! Like how a room full of monkeys with typewriters occasionally produces Shakespeare.</p> <h2 id="enter-egg-the-game-changer-">Enter egg: The Game Changer 🥚</h2> <p>For years, e-graphs were like fusion power - always 10 years away from being practical. They were slow, hard to implement, and each one was a custom job. Then came <strong>egg</strong> <a href="https://arxiv.org/abs/2004.03082">Willsey et al., “egg: Fast and extensible equality saturation,” POPL 2021</a> (e-graphs good!).</p> <h3 id="why-egg-changed-everything">Why egg Changed Everything</h3> <p>Before egg: “I’ll spend 6 months implementing an e-graph for my specific problem” After egg: “I’ll have a working optimizer by lunch”</p> <p><strong>The Secret Sauce:</strong></p> <ol> <li> <p><strong>Rebuilding Magic:</strong> Instead of constantly maintaining the e-graph (expensive!), egg says “let’s batch everything and fix it periodically.” It’s like cleaning your room once a week instead of after every sock.</p> </li> <li><strong>E-class Analysis:</strong> This is the killer feature. You can attach arbitrary data to e-classes. Is this expression a constant? What’s its type? Does it have side effects? Now your rewrites can be smart: <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Only optimize division if we know it's not divide-by-zero!</span>
<span class="nd">rewrite!</span><span class="p">(</span><span class="s">"div-safe"</span><span class="p">;</span> <span class="s">"(/ ?x ?y)"</span> <span class="k">=&gt;</span> <span class="s">"?x"</span> <span class="k">if</span> <span class="nf">is_one</span><span class="p">(</span><span class="o">?</span><span class="n">y</span><span class="p">))</span>
</code></pre></div> </div> </li> <li><strong>It’s FAST:</strong> 20× faster than previous implementations. That’s the difference between waiting minutes and waiting days.</li> </ol> <h3 id="e-class-analysis-making-your-e-graph-smart">E-class Analysis: Making Your E-graph Smart</h3> <p>Remember how I said e-graphs keep all equivalent expressions? Well, what if each group could also remember facts about itself? That’s e-class analysis.</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// "Hey e-graph, remember that this expression is always positive"</span>
<span class="c1">// "This one is a constant with value 42"</span>
<span class="c1">// "This expression has no side effects"</span>
</code></pre></div></div> <p><strong>Real Examples:</strong></p> <p><strong>Constant Folding:</strong></p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">analysis</span><span class="p">:</span> <span class="n">ConstantFold</span>
<span class="n">e</span><span class="o">-</span><span class="n">class</span><span class="p">:</span> <span class="p">{</span><span class="mi">2</span><span class="o">+</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="o">&lt;&lt;</span><span class="mi">1</span><span class="p">}</span>
<span class="n">analysis</span> <span class="n">says</span><span class="p">:</span> <span class="s">"BTW, this whole e-class equals 4"</span>
</code></pre></div></div> <p><strong>Range Analysis:</strong></p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">analysis</span><span class="p">:</span> <span class="n">IntervalAnalysis</span>  
<span class="n">e</span><span class="o">-</span><span class="n">class</span><span class="p">:</span> <span class="p">{</span><span class="n">x</span><span class="o">*</span><span class="n">x</span><span class="p">,</span> <span class="nf">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">2</span><span class="p">)}</span>
<span class="n">analysis</span> <span class="n">says</span><span class="p">:</span> <span class="s">"This is always ≥ 0"</span>
<span class="c1">// Now you can optimize sqrt(x*x) → abs(x)!</span>
</code></pre></div></div> <p>It’s like each e-class has a personal assistant keeping track of important facts.</p> <h3 id="conditional-rewrites-smart-optimizations">Conditional Rewrites: Smart Optimizations</h3> <p>With e-class analysis, your rewrites can be conditional. It’s like having optimization rules that say “only do this if you’re sure it’s safe.”</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Old way: "Always optimize x/y to something"</span>
<span class="c1">// New way: "Only optimize x/y if y isn't zero"</span>

<span class="nd">rewrite!</span><span class="p">(</span><span class="s">"safe-div"</span><span class="p">;</span> <span class="s">"(/ ?x ?y)"</span> <span class="k">=&gt;</span> <span class="s">"?x"</span> 
  <span class="k">if</span> <span class="nf">is_one</span><span class="p">(</span><span class="o">?</span><span class="n">y</span><span class="p">));</span>  <span class="c1">// Only if y = 1</span>

<span class="nd">rewrite!</span><span class="p">(</span><span class="s">"pythagoras"</span><span class="p">;</span> <span class="s">"(sqrt (+ (* ?x ?x) (* ?y ?y)))"</span> <span class="k">=&gt;</span> <span class="s">"(abs ?z)"</span>
  <span class="k">if</span> <span class="nf">is_complex</span><span class="p">(</span><span class="o">?</span><span class="n">z</span><span class="p">)</span> <span class="o">&amp;&amp;</span> <span class="o">?</span><span class="n">z</span> <span class="o">=</span> <span class="o">?</span><span class="n">x</span> <span class="o">+</span> <span class="o">?</span><span class="n">y</span><span class="o">*</span><span class="n">i</span><span class="p">);</span>  <span class="c1">// Complex number optimization!</span>
</code></pre></div></div> <p><strong>My Favorite Examples:</strong></p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Strength reduction, but only for powers of 2</span>
<span class="nd">rewrite!</span><span class="p">(</span><span class="s">"mul-to-shift"</span><span class="p">;</span> <span class="s">"(* ?x ?c)"</span> <span class="k">=&gt;</span> <span class="s">"(&lt;&lt; ?x ?n)"</span>
  <span class="k">if</span> <span class="nf">is_power_of_two</span><span class="p">(</span><span class="o">?</span><span class="n">c</span><span class="p">)</span> <span class="o">&amp;&amp;</span> <span class="o">?</span><span class="n">n</span> <span class="o">=</span> <span class="nf">log2</span><span class="p">(</span><span class="o">?</span><span class="n">c</span><span class="p">));</span>

<span class="c1">// Remove assertions that we can prove are true</span>
<span class="nd">rewrite!</span><span class="p">(</span><span class="s">"remove-true-assert"</span><span class="p">;</span> <span class="s">"(assert ?cond ?expr)"</span> <span class="k">=&gt;</span> <span class="s">"?expr"</span>
  <span class="k">if</span> <span class="nf">can_prove</span><span class="p">(</span><span class="o">?</span><span class="n">cond</span><span class="p">));</span>
</code></pre></div></div> <p>It’s optimization with a brain!</p> <h2 id="quick-comparison-traditional-vs-e-graphs">Quick Comparison: Traditional vs E-graphs</h2> <p>Let me break it down for you:</p> <table> <thead> <tr> <th>Feature</th> <th>Traditional Term Rewriting</th> <th>E-graphs + Equality Saturation</th> </tr> </thead> <tbody> <tr> <td><strong>Core Idea</strong></td> <td>Apply one rule at a time, destroy the original</td> <td>Keep everything, explore all paths</td> </tr> <tr> <td><strong>Analogy</strong></td> <td>Following a strict recipe</td> <td>Detective’s corkboard with red string</td> </tr> <tr> <td><strong>Phase Ordering</strong></td> <td>“Pick the right order or suffer”</td> <td>“What’s phase ordering?” 😎</td> </tr> <tr> <td><strong>Optimization Quality</strong></td> <td>Depends on rule order</td> <td>Finds optimal (given enough time)</td> </tr> <tr> <td><strong>Speed</strong></td> <td>Fast per rule</td> <td>Slower but does everything at once</td> </tr> <tr> <td><strong>Memory Usage</strong></td> <td>Minimal</td> <td>“RAM is cheap, right?”</td> </tr> <tr> <td><strong>When to Use</strong></td> <td>Simple, local optimizations</td> <td>Complex, whole-program optimization</td> </tr> <tr> <td><strong>Main Weakness</strong></td> <td>Gets stuck in local optima</td> <td>Extraction is NP-hard</td> </tr> </tbody> </table> <h2 id="real-world-success-stories">Real-World Success Stories</h2> <h3 id="herbie-making-floating-point-math-not-suck">Herbie: Making Floating-Point Math Not Suck</h3> <p>Floating-point arithmetic is where good programmers go to cry. You write <code class="language-plaintext highlighter-rouge">sqrt(x+1) - sqrt(x)</code> and for large x, you get… 0? Thanks, floating point! Enter Herbie <a href="https://herbie.uwplse.org/pldi15-paper.pdf">Panchekha et al., “Automatically improving accuracy for floating point expressions,” PLDI 2015</a>.</p> <p><strong>The Herbie Magic:</strong> Herbie uses egg to find mathematically equivalent expressions that don’t suffer from catastrophic cancellation:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Original: sqrt(x+1) - sqrt(x)
Problem: When x is large, both sqrts are nearly equal → precision loss

Herbie finds: 1/(sqrt(x+1) + sqrt(x))
Why better: No subtraction of nearly-equal numbers!
</code></pre></div></div> <p><strong>The Punchline:</strong></p> <ul> <li>3000× faster than the old Herbie (not a typo!)</li> <li>Accuracy improved from 53% to 99.7%</li> <li>Turns numerical analysis PhD problems into “push button, get answer”</li> </ul> <p>I’ve used Herbie on real code. It’s like having a numerical analysis expert on speed dial.</p> <h3 id="hardware-design-making-chips-cheaper">Hardware Design: Making Chips Cheaper</h3> <p><strong>The Problem:</strong> You’re designing a chip. Every gate costs money. Every nanosecond of delay costs performance.</p> <p><strong>E-graphs to the Rescue:</strong></p> <div class="language-verilog highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Original hardware:</span>
<span class="n">result</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span> <span class="o">?</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span> <span class="o">:</span> <span class="mi">0</span>

<span class="c1">// E-graph finds:</span>
<span class="n">result</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span> <span class="o">?</span> <span class="mi">2</span><span class="o">*</span><span class="n">y</span> <span class="o">:</span> <span class="mi">0</span>  <span class="c1">// One less adder input!</span>
</code></pre></div></div> <p><strong>Real Example from E-Syn:</strong> They used egg + machine learning to optimize hardware designs:</p> <ol> <li>E-graph explores equivalent circuits</li> <li>ML model predicts area/delay without synthesis</li> <li>Pick the best one</li> </ol> <p>Result? 30% smaller circuits with same functionality. That’s millions of dollars saved in chip production!</p> <h3 id="compiler-magic-cranelift-and-friends">Compiler Magic: Cranelift and Friends</h3> <p><strong>Cranelift ægraphs:</strong> WebAssembly’s compiler using e-graphs:</p> <ul> <li>Problem: How do you apply e-graphs when you have control flow?</li> <li>Solution: “Let’s just e-graph the straight-line code and keep the control flow separate”</li> <li>Result: Fast compilation with good optimization</li> </ul> <p><strong>Diospyros</strong> <a href="https://dl.acm.org/doi/10.1145/3445814.3446707">VanHattum et al., “Vectorization for digital signal processors via equality saturation,” ASPLOS 2021</a>: Vectorization on steroids:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>// Original loop:
for i in 0..n:
    c[i] = sqrt(a[i]) + b[i]

// Diospyros finds the exact vector instructions:
vec_sqrt_add(a, b)  // One instruction instead of n*2!
</code></pre></div></div> <p><strong>The Catch:</strong> E-graphs can explode for large programs. Optimizing 8×8×8 matrix multiply? Hope you have RAM to spare!</p> <p><strong>Isaria’s Innovation:</strong> “What if we automatically learned rewrite rules from the instruction manual?”</p> <ul> <li>Feed it ISA documentation</li> <li>It generates rewrite rules automatically</li> <li>Your compiler understands new instructions without manual work</li> </ul> <h2 id="egglog-the-next-generation-">Egglog: The Next Generation 🤯</h2> <h3 id="what-if-e-graphs-could-think">What if E-graphs Could Think?</h3> <p>Egglog <a href="https://arxiv.org/abs/2304.04332">Zhang et al., “Better Together: Unifying Datalog and Equality Saturation,” PLDI 2023</a> is what happens when someone looks at e-graphs and says “this is cool, but what if we added Prolog?” It’s e-graphs meets logic programming, and it’s wild.</p> <p><strong>The Big Idea:</strong> Instead of just tracking equivalences, what if we could reason about relationships?</p> <div class="language-prolog highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">//</span> <span class="nv">Traditional</span> <span class="ss">e</span><span class="o">-</span><span class="ss">graph</span><span class="o">:</span> <span class="s2">"These expressions are equal"</span>
<span class="o">//</span> <span class="nv">Egglog</span><span class="o">:</span> <span class="s2">"These expressions are equal AND here's why AND here's what else we can deduce"</span>
</code></pre></div></div> <p><strong>Example That Blew My Mind:</strong></p> <pre><code class="language-datalog">(datatype Math
  (Num i64)
  (Add Math Math)
  (Mul Math Math))

// Normal rewrites
(rewrite (Add (Num 0) x) x)
(rewrite (Mul (Num 1) x) x)

// But also relations!
(relation is-positive (Math))
(rule ((= x (Mul y y))) ((is-positive x)))  // Squares are positive

// Now optimizations can use reasoning
(rewrite (sqrt (Mul x x)) x 
  if (is-positive x))  // Safe because we proved it!
</code></pre> <h3 id="egglog-superpowers">Egglog Superpowers</h3> <p><strong>Program Analysis on Steroids:</strong></p> <pre><code class="language-datalog">// "Which basic blocks can reach the exit?"
(relation reaches-exit (BasicBlock))
(rule ((is-exit ?block)) ((reaches-exit ?block)))
(rule ((edge ?from ?to) (reaches-exit ?to)) 
      ((reaches-exit ?from)))

// Now optimize: "Remove code that can't reach exit!"
</code></pre> <p><strong>Incremental Everything:</strong></p> <ul> <li>Your program changed? Egglog updates just what’s needed</li> <li>No more “rebuild the world” after every edit</li> <li>It’s like Git for your optimizer’s brain</li> </ul> <p><strong>The Killer App I’m Waiting For:</strong> Security analysis + optimization in one pass. “This is equivalent AND secure AND fast.”</p> <h2 id="the-future-where-this-is-all-going">The Future: Where This is All Going</h2> <h3 id="the-scalability-wall">The Scalability Wall</h3> <p>Current challenge: E-graphs get HUGE for big programs. Like, “eat all your RAM and ask for seconds” huge.</p> <h3 id="ml--e-graphs--️">ML + E-graphs = ❤️</h3> <p>The hot new thing: Teaching e-graphs to be smarter with machine learning.</p> <p><strong>Learning What’s Important:</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Old way: Try everything!
# New way: ML says "try this first, it usually works"
</span><span class="n">model</span><span class="p">.</span><span class="nf">predict_best_rewrite</span><span class="p">(</span><span class="n">expression</span><span class="p">)</span>
</code></pre></div></div> <p>There are some works on EGRAPH 2025 for this topic.</p> <h3 id="the-theory-gap">The Theory Gap</h3> <p>We’re using e-graphs everywhere, but the theory is playing catch-up:</p> <ul> <li>When exactly does equality saturation terminate?</li> <li>Can we prove extraction finds the optimal solution?</li> <li>What are the complexity bounds?</li> </ul> <p>It’s like we invented cars before understanding thermodynamics. It works, but we’re not always sure why!</p> <h2 id="wrapping-up-why-this-matters">Wrapping Up: Why This Matters</h2> <h3 id="the-journey-so-far">The Journey So Far</h3> <p>We’ve come a long way from “apply rules and hope for the best”:</p> <ol> <li><strong>Term Rewriting</strong>: The old way. One rule at a time, fingers crossed.</li> <li><strong>E-graphs</strong>: Keep everything! Build a map of all possibilities.</li> <li><strong>Equality Saturation</strong>: Explore everything! Find the best path.</li> <li><strong>egg</strong>: Make it fast and usable for mortals.</li> <li><strong>Egglog</strong>: Add reasoning and logic to the mix.</li> </ol> <h3 id="why-you-should-care">Why You Should Care</h3> <p>E-graphs aren’t just another optimization technique. They’re a fundamentally different way of thinking about program transformation:</p> <p><strong>Before</strong>: “What’s the right order to apply optimizations?” <strong>After</strong>: “What if we didn’t have to choose?”</p> <p>It’s like the difference between taking one photo and hoping it’s good vs. taking 1000 photos and picking the best one. Except the camera (egg) is really fast now.</p> <h3 id="my-take">My Take</h3> <p>After working with e-graphs, going back to traditional optimization feels like coding with one hand tied behind my back. Yes, extraction is NP-hard. Yes, e-graphs can explode in size. But the ability to explore the entire optimization space and <em>know</em> you’re not missing opportunities? That’s powerful.</p> <h3 id="the-bottom-line">The Bottom Line</h3> <p>E-graphs and equality saturation represent a paradigm shift in how we think about optimization. By keeping all possibilities alive and exploring them simultaneously, we’ve opened doors that were previously locked by the phase ordering problem.</p> <p>Is it perfect? No. Is it the future? I think so.</p>]]></content><author><name></name></author><category term="survey"/><category term="term-rewriting"/><category term="e-graphs"/><category term="optimization"/><summary type="html"><![CDATA[How e-graphs turn the optimizer's dilemma into a solved problem by keeping all the good ideas at once, featuring real examples, bad jokes, and the magic of egg]]></summary></entry><entry><title type="html">Glancing at the Simulation Landscape</title><link href="https://uv-xiao.github.io/blog/2025/sim/" rel="alternate" type="text/html" title="Glancing at the Simulation Landscape"/><published>2025-07-01T00:00:00+00:00</published><updated>2025-07-01T00:00:00+00:00</updated><id>https://uv-xiao.github.io/blog/2025/sim</id><content type="html" xml:base="https://uv-xiao.github.io/blog/2025/sim/"><![CDATA[<p>Recent papers to read:</p> <ul class="task-list"> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>Assassyn: A Unified Abstraction for Architectural Simulation and Implementation</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>Concorde: Fast and Accurate CPU Performance Modeling with Compositional Analytical-ML Fusion</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>Performance Interfaces for Hardware Accelerators</li> </ul> <p>Maybe write things for each of them? If I have time🥹</p> <h1 id="the-simulation-landscape-pick-your-poison">The Simulation Landscape: Pick Your Poison</h1> <p>Ever had a brilliant idea for a new processor feature at 2 AM? Maybe you thought, “what if we had a cache that could predict the future?” or “could we make branch prediction psychic?” Welcome to the wonderful, frustrating, occasionally maddening world of computer architecture simulation!</p> <p>Choosing the right simulator is like picking a character in an RPG: Do you go for the slow, powerful wizard (gem5) that can model anything but takes forever? Or the speedy rogue (zSim) that gets you results fast but might miss some details? Maybe you’re feeling rich and want the ultimate pay-to-win option (FireSim on AWS)?</p> <p>After years of banging my head against various simulators (and occasionally wanting to throw my laptop out the window), I’ve learned that each tool has its own personality, quirks, and sweet spots. This post is my attempt to save you some pain and help you pick the right tool for your research without losing your sanity.</p> <h2 id="architectural-simulators-where-dreams-meet-reality-very-very-slowly">Architectural Simulators: Where Dreams Meet Reality (Very, Very Slowly)</h2> <p>Architectural simulators are where most of us start our journey. These bad boys model your processor at the microarchitectural level - think pipelines, caches, branch predictors, the works. The catch? They’re not exactly speed demons. But hey, when you need to know <em>exactly</em> how many cycles your brilliant idea saves, these are your friends.</p> <h3 id="gem5-the-all-powerful-all-complicated-behemoth">gem5: The All-Powerful, All-Complicated Behemoth</h3> <p>Ah, gem5 <a href="https://research.cs.wisc.edu/multifacet/papers/can11_gem5.pdf">Binkert et al., “The gem5 simulator,” 2011</a>. If computer architecture simulators were cars, gem5 would be a Formula 1 car that you have to assemble yourself from 10,000 parts while reading documentation written by someone who assumes you already built five F1 cars.</p> <p><strong>The Good:</strong></p> <ul> <li>Can model basically anything. Want a 128-core processor with a telepathic cache? gem5’s got you.</li> <li>Multiple CPU models from dead simple (AtomicSimple) to “why does this have so many pipeline stages” (O3)</li> <li>Full-system simulation - yes, it can boot Linux. Very. Very. Slowly.</li> <li>Supports every ISA under the sun: ARM, x86, RISC-V, and probably some alien architectures</li> </ul> <p><strong>The Reality Check:</strong></p> <ul> <li>Simulation speed: 10-200 KIPS. That’s Kilo-Instructions Per Second. Not Mega. Not Giga. <em>Kilo</em>.</li> <li>My first gem5 setup took a week and more coffee than I care to admit</li> <li>The configuration system is “flexible” in the same way quantum mechanics is “intuitive”</li> <li>Memory usage scales with complexity - I’ve seen gem5 eat 64GB of RAM and ask for seconds</li> </ul> <p><strong>When to Use gem5:</strong></p> <ul> <li>Your advisor said “use gem5” (the most common reason)</li> <li>You need to publish a paper and reviewers expect gem5 results</li> <li>You’re modeling something genuinely novel that needs cycle-accurate detail</li> <li>You have infinite patience or really good coffee</li> </ul> <p><strong>Pro Tip:</strong> Start with the gem5 bootcamp examples. Don’t try to build your dream processor on day one. Trust me on this.</p> <h3 id="zsim-the-speed-demon-from-mit">zSim: The Speed Demon from MIT</h3> <p>zSim <a href="https://people.csail.mit.edu/sanchez/papers/2013.zsim.isca.pdf">Sanchez &amp; Kozyrakis, “ZSim: Fast and accurate microarchitectural simulation of thousand-core systems,” ISCA 2013</a> is what happens when someone at MIT gets fed up with gem5’s speed and decides to do something about it. The result? A simulator that’s actually fast enough to finish experiments before the conference deadline.</p> <p><strong>The Magic Sauce:</strong></p> <ul> <li><strong>Bound-Weave Parallelization</strong>: Sounds fancy, but basically means “we figured out how to parallelize the hell out of this”</li> <li><strong>Pin-based execution</strong>: Rides on Intel Pin like a rocket-powered skateboard</li> <li><strong>Instruction-driven timing</strong>: Instead of simulating every cycle (like gem5’s masochistic approach), zSim says “let’s just figure out how long each instruction takes”</li> </ul> <p><strong>Real Talk Performance:</strong></p> <ul> <li>10s to 1000s MIPS - that’s <em>Millions</em> with an M!</li> <li>I’ve seen 100× speedups over gem5. Not a typo.</li> <li>Can actually simulate real workloads without growing a beard</li> </ul> <p><strong>The Catch:</strong></p> <ul> <li>Less detailed than gem5 (but often good enough)</li> <li>x86-only last I checked</li> <li>Some microarchitectural details are approximated</li> </ul> <p><strong>When to Use zSim:</strong></p> <ul> <li>You need results this decade</li> <li>You’re studying multicore systems (it scales beautifully)</li> <li>Your research is more about cache hierarchies than pipeline details</li> <li>You value your sanity</li> </ul> <h3 id="sst-when-you-need-to-simulate-a-supercomputer">SST: When You Need to Simulate a Supercomputer</h3> <p>SST <a href="https://dl.acm.org/doi/10.1145/1964218.1964225">Rodrigues et al., “The structural simulation toolkit,” ACM SIGMETRICS 2011</a> is what happens when the folks at Sandia National Labs need to simulate something bigger than your average processor. This is the tool for when you’re thinking less “how many cache misses?” and more “how do 10,000 nodes talk to each other without catching fire?”</p> <p><strong>What Makes SST Special:</strong></p> <ul> <li>Component-based design - like LEGO blocks for supercomputers</li> <li>Actually runs in parallel (because simulating parallel systems serially is just sad)</li> <li>Plays nice with other simulators - the diplomatic option</li> <li>Network modeling that doesn’t make you cry</li> </ul> <p><strong>Perfect For:</strong></p> <ul> <li>“I need to simulate an entire datacenter” problems</li> <li>Network topology research (mesh? torus? hypercube? SST’s got you)</li> <li>When your scale unit is racks, not cores</li> </ul> <h3 id="dam-for-when-von-neumann-just-isnt-weird-enough">DAM: For When Von Neumann Just Isn’t Weird Enough</h3> <p>DAM <a href="https://ppl.stanford.edu/papers/DAM_ISCA24.pdf">Zhang et al., “The Dataflow Abstract Machine Simulator Framework,” ISCA 2024</a> is the rebel of the simulation world. While everyone else is simulating nice, orderly von Neumann machines, DAM is over here simulating dataflow architectures - where data flows like water and control flow is more of a suggestion.</p> <p>DAM uses a clever CSP (Communicating Sequential Processes) programming model with “contexts” (nodes) and “channels” (edges). It avoids global synchronization bottlenecks through a scalable point-to-point scheme, making it possible to simulate systems with thousands of components. Think of it as building a massive water park where each slide (context) runs independently, connected by pipes (channels) that handle the flow timing automatically.</p> <p><strong>The Dataflow Difference:</strong></p> <ul> <li>No program counter? No problem!</li> <li>Event-driven simulation because instructions execute when they damn well please</li> <li>Perfect for those “what if we completely rethink computing” moments</li> </ul> <p><strong>Use This When:</strong></p> <ul> <li>You’re exploring dataflow processors (there are dozens of us!)</li> <li>Stream processing is your jam</li> <li>You enjoy explaining to people why your processor doesn’t have a program counter</li> </ul> <h3 id="compiler-driven-simulation-when-your-compiler-becomes-a-crystal-ball">Compiler-Driven Simulation: When Your Compiler Becomes a Crystal Ball</h3> <p>This approach <a href="https://arxiv.org/abs/2202.00739">Li et al., “Compiler-Driven Simulation of Reconfigurable Hardware Accelerators,” HPCA 2022</a> is the new hotness - letting your compiler figure out how fast your accelerator will run before you even build it. It’s like having a fortune teller for your hardware designs, except it actually works (most of the time).</p> <p><strong>The EQueue Magic:</strong> The paper introduces the Event Queue (EQueue) dialect of MLIR that sits perfectly between “too low-level” RTL and “too high-level” models. EQueue can:</p> <ul> <li>Model arbitrary hardware with explicit data movement</li> <li>Use distributed event-based control (no global clock headaches!)</li> <li>Guide design improvements with visualizable outputs</li> <li>Match RTL accuracy while being way easier to modify</li> </ul> <p><strong>Real Impact:</strong> They showed it working on systolic arrays and SIMD processors, proving you can have your cake (accuracy) and eat it too (fast iteration).</p> <p><strong>Why This is Actually Cool:</strong></p> <ul> <li>Design space exploration without wanting to quit grad school</li> <li>Test 100 accelerator variants in the time it takes to simulate one in RTL</li> <li>Hardware/software co-design that doesn’t require a PhD in both</li> </ul> <h2 id="rtl-simulators-where-the-rubber-meets-the-road">RTL Simulators: Where the Rubber Meets the Road</h2> <h3 id="verilator-the-peoples-champion-of-rtl-simulation">Verilator: The People’s Champion of RTL Simulation</h3> <p>Verilator <a href="https://veripool.org/papers/">Snyder, “Verilator and SystemPerl,” 2004</a> is what happens when the open-source community says “screw expensive commercial simulators” and builds something better. It takes your Verilog, turns it into C++, and runs it at speeds that make other simulators jealous.</p> <p><strong>Why Verilator Rocks:</strong></p> <ul> <li>Verilog → C++ → ZOOM ZOOM</li> <li>Free as in freedom (and beer)</li> <li>Actually fast enough to run real software on your simulated CPU</li> <li>Used by basically every RISC-V project ever</li> </ul> <p><strong>The Speed Secret:</strong></p> <ul> <li>Compiles your hardware to software (meta, right?)</li> <li>No interpreter overhead - just raw compiled code</li> <li>I’ve seen 100× speedups over traditional simulators</li> </ul> <p><strong>Perfect For:</strong></p> <ul> <li>“I need to verify my RISC-V core” (join the club!)</li> <li>Pre-silicon software development</li> <li>When you need cycle-accurate but also want results today</li> <li>Impressing your friends with open-source superiority</li> </ul> <h3 id="cuttlesim-for-the-functional-programming-hardware-nerds">Cuttlesim: For the Functional Programming Hardware Nerds</h3> <p>Cuttlesim <a href="https://pit-claudel.fr/clement/papers/cuttlesim-ASPLOS21.pdf">Pit-Claudel et al., “Effective simulation and debugging for a high-level hardware language using software compilers,” ASPLOS 2021</a> is what you get when someone looks at Verilog and says “you know what this needs? More monads!” It’s the simulator for Koika, a hardware description language that brings functional programming to hardware design.</p> <p><strong>The Secret Sauce:</strong> Cuttlesim beats state-of-the-art RTL simulators by 2-5× by being smart about Koika’s “early-exit” semantics. Instead of simulating every wire wiggle, it compiles rules directly to C++ that’s optimized for how CPUs actually work. The generated code is so clean you can debug your hardware using GDB. Yes, really.</p> <p><strong>The Koika Philosophy:</strong></p> <ul> <li>Hardware as concurrent rules that <em>appear</em> atomic (mind = blown)</li> <li>Formal verification built-in (bugs are so mainstream)</li> <li>Think Bluespec but with a PhD in type theory</li> <li>People who think Verilog isn’t abstract enough</li> <li>Researchers exploring “what if hardware design didn’t suck?”</li> <li>Those who enjoy explaining monads AND flip-flops at parties</li> </ul> <h2 id="the-speed-accuracy-trade-off-visualized">The Speed-Accuracy Trade-off Visualized</h2> <p>Before we dive into FPGA solutions, let me show you the fundamental trade-off in simulation land:</p> <pre><code class="language-mermaid">quadrantChart
    title Simulation Speed vs. Accuracy Trade-off
    x-axis "Slow as Molasses" --&gt; "Actually Usable"
    y-axis "Good Enough" --&gt; "Cycle-Perfect"
    quadrant-1 "Academic Gold Standard"
    quadrant-2 "Sweet Spot"
    quadrant-3 "Why Bother?"
    quadrant-4 "Quick &amp; Dirty"
    "gem5": [0.4, 0.6]
    "Verilator": [0.15, 0.85]
    "SST": [0.7, 0.55]
    "zSim": [0.8, 0.4]
    "FireSim": [0.85, 0.85]
    "Compiler-Driven": [0.5, 0.35]
</code></pre> <h2 id="fpga-emulation-when-software-just-isnt-cutting-it">FPGA Emulation: When Software Just Isn’t Cutting It</h2> <h3 id="firesim-the-i-have-grant-money-option">FireSim: The “I Have Grant Money” Option</h3> <p>FireSim <a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2018/EECS-2018-154.pdf">Karandikar et al., “FireSim: FPGA-accelerated cycle-exact scale-out system simulation in the public cloud,” ISCA 2018</a> is what happens when Berkeley researchers look at AWS F1 instances and think “you know what would be cool? Simulating an entire datacenter on these bad boys.” And then they actually did it, the absolute madlads.</p> <p><strong>The FireSim Magic:</strong></p> <ul> <li><strong>Golden Gate Compiler</strong>: Takes your RTL and makes it cloud-ready (no sacrifice required)</li> <li><strong>AWS F1 Integration</strong>: Hope you have that grant money ready!</li> <li><strong>Distributed Simulation</strong>: Because why simulate one chip when you can simulate thousands?</li> </ul> <p><strong>What You Can Actually Do:</strong></p> <ul> <li>Simulate thousands of cores without your lab catching fire</li> <li>Run real software stacks at decent speeds</li> <li>Test datacenter-scale ideas without buying a datacenter</li> <li>Make your advisor very happy (and very poor)</li> </ul> <p><strong>Performance That Makes You Smile:</strong></p> <ul> <li>10-100× faster than software simulation</li> <li>Can run real workloads in reasonable time</li> <li>Network simulation that actually behaves like a network</li> </ul> <p><strong>The Price of Glory:</strong></p> <ul> <li>AWS bills that make you question your life choices</li> <li>Setup complexity that requires a PhD in cloud computing</li> <li>“Did you remember to terminate those instances?” anxiety</li> </ul> <p><strong>Perfect For:</strong></p> <ul> <li>Datacenter research with actual scale</li> <li>“What if we had 1000 cores?” questions</li> <li>Impressing reviewers with scale</li> <li>Spending someone else’s money on AWS</li> </ul> <h2 id="the-bottom-line-which-simulator-should-you-use">The Bottom Line: Which Simulator Should You Use?</h2> <p>After all this, you’re probably wondering “just tell me which one to use!” Here’s my totally biased but battle-tested advice:</p> <h3 id="the-quick-reference-guide">The Quick Reference Guide</h3> <table class="table-responsive"> <thead> <tr> <th style="text-align: left">Simulator</th> <th style="text-align: center">Speed</th> <th style="text-align: center">Accuracy</th> <th style="text-align: left">Best For</th> <th style="text-align: left">Avoid If</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">gem5</td> <td style="text-align: center">🐌</td> <td style="text-align: center">🎯🎯[🎯]?</td> <td style="text-align: left">Papers, microarch details</td> <td style="text-align: left">You have deadlines</td> </tr> <tr> <td style="text-align: left">zSim</td> <td style="text-align: center">🚀🚀</td> <td style="text-align: center">🎯[🎯]?</td> <td style="text-align: left">Multicore, cache studies</td> <td style="text-align: left">You need RTL accuracy</td> </tr> <tr> <td style="text-align: left">SST</td> <td style="text-align: center">🚀</td> <td style="text-align: center">🎯🎯</td> <td style="text-align: left">Networks, large systems</td> <td style="text-align: left">You’re studying single cores</td> </tr> <tr> <td style="text-align: left">Verilator</td> <td style="text-align: center">🐌🐌</td> <td style="text-align: center">🎯🎯🎯</td> <td style="text-align: left">RTL verification</td> <td style="text-align: left">You hate Verilog</td> </tr> <tr> <td style="text-align: left">FireSim</td> <td style="text-align: center">🚀🚀</td> <td style="text-align: center">🎯🎯🎯</td> <td style="text-align: left">Scale + accuracy</td> <td style="text-align: left">You’re paying</td> </tr> </tbody> </table> <h3 id="what-each-tool-does-best">What Each Tool Does Best</h3> <ul> <li><strong>Need to model a complex out-of-order core?</strong> gem5 (and patience)</li> <li><strong>Studying cache hierarchies?</strong> zSim all day</li> <li><strong>Building a network-on-chip?</strong> SST has your back</li> <li><strong>Verifying your Verilog?</strong> Verilator is your friend</li> <li><strong>Prefering rule-based HDLs?</strong> Cuttlesim</li> <li><strong>Simulating a datacenter?</strong> FireSim (and a credit card)</li> <li><strong>Exploring weird architectures?</strong> DAM/EQueue for dataflow</li> </ul> <h3 id="the-learning-curve-reality-check">The Learning Curve Reality Check</h3> <ul> <li><strong>“I Can Figure This Out in a Day”</strong>: Verilator (if you know Verilog)</li> <li><strong>“Give Me a Week”</strong>: zSim, SST basics</li> <li><strong>“This is My Semester Project”</strong>: gem5 mastery, FireSim setup</li> <li><strong>“I Now Have Stockholm Syndrome”</strong>: gem5 Ruby, custom FPGA platforms</li> </ul> <h2 id="wheres-this-all-going-the-crystal-ball-section">Where’s This All Going? The Crystal Ball Section</h2> <h3 id="ml-everything-because-of-course">ML Everything (Because Of Course)</h3> <p>Everyone’s slapping ML onto their simulators now:</p> <ul> <li><strong>Performance Prediction</strong>: “What if we just guess instead of simulating?” (Sometimes works!)</li> <li><strong>Smart Workload Generation</strong>: ML picks representative benchmarks so you don’t have to</li> <li><strong>Design Space Exploration</strong>: Let the robots find your optimal cache size</li> </ul> <h2 id="wrapping-up-the-survival-guide">Wrapping Up: The Survival Guide</h2> <h3 id="the-philosophy">The Philosophy</h3> <p>At the end of the day, simulators are just tools. The best simulator is the one that answers your research question without driving you to madness. Sometimes that’s gem5 grinding away for days. Sometimes it’s a quick zSim run that gets you 80% of the answer in an hour.</p> <p>Choose wisely, simulate responsibly, and remember: every KIPS of gem5 simulation is building character. Or at least that’s what I tell myself while waiting for results.</p> <p>Happy simulating! May your runs be fast and your results be publishable. 🚀</p> <hr/> <h2 id="appendix-resources-that-will-actually-help">Appendix: Resources That Will Actually Help</h2> <h3 id="getting-started-guides-that-dont-suck">Getting Started Guides That Don’t Suck</h3> <p><strong>gem5</strong>: Start with the <a href="https://github.com/gem5bootcamp/bootcamp">gem5 bootcamp</a>. Actually do the exercises. Yes, all of them.</p> <p><strong>zSim</strong>: The <a href="https://github.com/s5z/zsim">tutorial</a> is decent. The real learning happens when you try to add your first feature.</p> <p>… more to come</p>]]></content><author><name></name></author><category term="survey"/><category term="simulation"/><category term="architecture"/><summary type="html"><![CDATA[Survey on simulation tools for computer architecture research]]></summary></entry></feed>